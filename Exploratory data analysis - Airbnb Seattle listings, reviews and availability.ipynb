{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e94cf8",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "For this exploration of the data the files are read in and inspected for missing values, data types and availability of data needed to answer business questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a59eae",
   "metadata": {},
   "source": [
    "# Analysis plan\n",
    "The datasets consists of three files, `calendar` entries, property `listings` and `reviews`. The `reviews` data file will be ignored for this project due to it only containing text information and NLP is out of scope.\n",
    "\n",
    "The goal of this project is to answer the following question in a blogpost:\n",
    "1. What influences the price of a stay in Seattle the most?\n",
    "\n",
    "This can be divided in two subquestions:\n",
    "1. Do prices get influenced by seasonal trends? (does it matter when you book your stay)\n",
    "1. Which factors influence a properties base listing price the most?\n",
    "  \n",
    "To answer these we'll start with basic data exploration and cleaning and finish up using a randomforest regressor to determine which features actually affect the price the most. During the initial cleaning of the data a subset of columns is dropped from the `listing` data, reasons explained below\n",
    "\n",
    "After both `calendar` and `listing` data is loaded in, the dataframes are joined together to enrich the dataset for further exploration, adding location data to the calendar overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_summary_overview(df):\n",
    "    \"\"\"Take a pandas DataFrame and display the shape, provide info on the columns\n",
    "    and display the 5 first and 5 last rows of the data. 5 last to see if there are total/summary\n",
    "    rows included in the data\n",
    "    \"\"\"\n",
    "    # print shape information\n",
    "    rows, columns = df.shape\n",
    "    print(f'This dataset has {rows} rows & {columns} columns\\n')\n",
    "    \n",
    "    # Display a small example\n",
    "    display(df.head(5))\n",
    "    display(df.tail(5))\n",
    "    \n",
    "    # Describe the dataframe\n",
    "    display(df.info(memory_usage=False))\n",
    "\n",
    "    \n",
    "## Cleaning data\n",
    "def clean_and_cast_price(price):\n",
    "    \"\"\"Take the price and clean the commas and dollar signs\"\"\"\n",
    "    if pd.isnull(price):\n",
    "        return price\n",
    "    else:\n",
    "        return price.replace('$','').replace(',','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4ef66",
   "metadata": {},
   "source": [
    "## Looking at the calendar data\n",
    "\n",
    "- The data has three columns and seems to only have missing values for the `price` column.\n",
    "- The `date` column is an object, for each of processing lets turn this into a datetime column\n",
    "- The `available` column is a boolean but is stored as object with t/f values.\n",
    "- The prices have a `$` symbol and are stored as objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and get summary overview\n",
    "calendar = pd.read_csv('data/airbnb_seatle/calendar.csv')\n",
    "df_summary_overview(calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b83b87",
   "metadata": {},
   "source": [
    "### Preprocess calendar data\n",
    "- Clean price column, remove $ and comma for thousands and cast to float\n",
    "- Cast the available column to boolean\n",
    "- Change the date column to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the $ sign from the price column, remove the commas (,) for the thousands and cast to float\n",
    "calendar.loc[:,'price'] = (calendar['price']\n",
    "                           .apply(clean_and_cast_price)\n",
    "                           .astype(float)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change available column to boolean\n",
    "calendar.loc[:,'available'] = calendar['available'] == 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update datetype for date\n",
    "calendar.loc[:,'date'] = pd.to_datetime(calendar['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081f7d1",
   "metadata": {},
   "source": [
    "### Explore calendar data\n",
    "- Check the missing values in the pricing column\n",
    "- See if some listings are missing all pricing information\n",
    "- Check pricing range, any outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot missing values\n",
    "(calendar.isnull().mean()*100).plot(kind='bar', figsize=(12,4), rot=0);\n",
    "\n",
    "# Only price seems to be missing, is there a pattern to which lines are missing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which dates the price is missing, looks like this might be tied to availability\n",
    "\n",
    "# Select only unavailable rooms, check unique list of prices\n",
    "print(f\"Unique prices in unavailable rooms: {calendar.loc[~calendar['available'],'price'].unique()}\")\n",
    "\n",
    "\n",
    "# Check null values in available listings\n",
    "print(f\"Available rooms, price unknown: {calendar.loc[calendar['available'],'price'].isnull().sum()}\")\n",
    "\n",
    "# So the prices for available rooms are known, when unavailable they are unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there properties for which the price is unknown?\n",
    "# Use groupby with maximum price to determine\n",
    "calendar_max_prices = calendar.groupby('listing_id').price.max()\n",
    "\n",
    "# listings missing prices, check listing data to get prices?\n",
    "calendar_listings_no_price = calendar_max_prices[calendar_max_prices.isnull()].index.tolist()\n",
    "\n",
    "\n",
    "print(f\"There are {len(calendar_listings_no_price)} listings that do not have a price in the calendar at all\")\n",
    "\n",
    "# Missing a price might be in the listings data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2547ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices per listing seem to change over time. Only ~13% of the listings have 1 price for the whole year,\\\n",
    "# The rest is subject to change\n",
    "\n",
    "number_of_pricings = calendar.groupby('listing_id').apply(lambda x: x.price.unique().size).value_counts()\n",
    "print(f'Number of listings with same price for the whole year: {number_of_pricings[1]/number_of_pricings.sum()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13722a8b",
   "metadata": {},
   "source": [
    "## Looking at the Listings data\n",
    "The listings data has a lot of columns with information around the listing. It includes summary summary statistics on the listing like number of reviews, average review rating, location of the listing and information about the listing in general.\n",
    "\n",
    "For the EDA, lets have a look at some of the columns and identify some columns that might provide interesting information we can use to answer questions.\n",
    "\n",
    "There are a bunch of columns that do not add any additional information, lets remove them to reduce the clutter the size of the dataset and make it easier to keep an overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2bed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listings = pd.read_csv('data/airbnb_seatle/listings.csv')\n",
    "df_summary_overview(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot missing values as percentage missing\n",
    "(listings.isnull().mean()*100)[~listings.notnull().all()].plot(kind='bar', figsize=(12,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa08f66",
   "metadata": {},
   "source": [
    "There are a few columns that are low information as they have a large percentage missing values. See below for a list of columns that will be dropped from the data.\n",
    "\n",
    "Next to that there are a few columns that have missing values that might be interesting. Two columns that stick out that might be interesting are `property_type` and `neighbourhood`. These are interesting as I want to have a look at the property type and neighbourhood influence on the price. Lets see if we can fill in the missing data.\n",
    "\n",
    "#### handling missing values for `property_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294e962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check only missing property with subset of values.\n",
    "listings[listings.property_type.isnull()][['id','name','summary','property_type','neighbourhood','bathrooms','bedrooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the homestead from the description to figure out which property_type uses this the most, fill that in\n",
    "listings[listings.name.str.contains('omestead')].property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in house as most used\n",
    "listings.loc[listings.id==3335,'property_type'] = 'House'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37333934",
   "metadata": {},
   "source": [
    "#### Investigate missing values in neighbourhood\n",
    "Instead of imputing the missing values in `neighbourhood` there is another column we could use instead, `neighbourhood_cleansed`, this doesn't have any empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[listings.neighbourhood.isnull()][['zipcode','neighbourhood','neighbourhood_cleansed']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d4145",
   "metadata": {},
   "source": [
    "#### Dropping low information columns from the listings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all low information columns, and columns with insufficient data to recover from missing data.\n",
    "\n",
    "drop_columns = [\n",
    "    'experiences_offered', # only none as value\n",
    "    \n",
    "    # Cleaning all URLs from the property\n",
    "    'thumbnail_url', # not interested in this, 320 missing, so around 90% of the properties have this\n",
    "    'medium_url',\n",
    "    'picture_url',\n",
    "    'xl_picture_url',\n",
    "    'host_url', # dropping as we have the host_id.\n",
    "    'host_thumbnail_url',\n",
    "    'host_picture_url',\n",
    "    \n",
    "    'city', # This is single value, Seattle, with very high generic flavours. Neighbourhood gives more information\n",
    "    'state', # Same as city, single value\n",
    "    'market', # single value, Seattle\n",
    "    'smart_location', # Same issue as city\n",
    "    'country_code', # one value\n",
    "    'country', # one value,\n",
    "    'jurisdiction_names', # one value\n",
    "    \n",
    "    'square_feet', # too many missing values that can't be recovered otherwise\n",
    "    'license' # Only missing values\n",
    "               ]\n",
    "\n",
    "listings = listings.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix listing price, removing $ signs and commas from all dollar amount columns\n",
    "price_cols = ['price','weekly_price','monthly_price', 'extra_people']\n",
    "listings.loc[:,price_cols] = (listings[price_cols]\n",
    "                             .applymap(clean_and_cast_price)\n",
    "                             .astype(float)\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if listings are duplicated based on the id column\n",
    "listings.id.value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c62f3",
   "metadata": {},
   "source": [
    "## Combine Calendar and Listings into one dataframe\n",
    "Enrich the calendar data set with the listings data of interest.\n",
    "\n",
    "\n",
    "**Filling missing prices**  \n",
    "To impute missing values for the calendar we'll use the last known value carried forward for missing prices. There are 95 properties that do not have any values in the calendar dataset, so forward filling the data will not work in that case. For those properties the price from the listing overview will be inserted.\n",
    "\n",
    "forward filling the data takes care of a lot of missing values but it doesn't cover all missing values. As mentioned for the 95 properties it doesn't insert any values, the forward fill will also fail to impute any missing values if the first observation of a property isn't known. To stay consistent with the 95 missing properties these values are filled using the price values as listed in the listings dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use groupby with a ffill to fill the missing values\n",
    "calendar.loc[:,'price_locf'] = (calendar\n",
    "                                .groupby('listing_id', as_index=False)\n",
    "                                .fillna(method='ffill')\n",
    "#                                 .fillna(method='bfill') # Use backfill to get latest value to populate forward\n",
    "                               ).price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9fd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calendar.merge(listings, left_on = 'listing_id', right_on = 'id', how='left', suffixes=('','_listings'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a90ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_coalesce'] = df.price_locf.combine_first(df.price_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19208ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check number of listings with any null values for the price\n",
    "df[df.price_coalesce.isnull()].listing_id.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b196e",
   "metadata": {},
   "source": [
    "### Data enrichment\n",
    "To make the analysis a little bit easier helper columns are introduced.\n",
    "- `date_month`; to get an easy overview per month\n",
    "- `day_of_week`; to inspect prices over the weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_month'] = df.date.dt.month_name()\n",
    "\n",
    "df['day_of_week'] = df.date.dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2026a9b",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Get a feel for how many lines of data we have, how many properties and with what price range. Look at some fields that from gut feeling might affect the price heavily, like property type and size of the property (how many people it accomodates).\n",
    "\n",
    "Plot the price distributions to see how the prices are distributed on the properties in Seattle. Add visual inspection of the price over time displaying the seasonal trend in the data.\n",
    "\n",
    "Lastly investigate the influence of the neighbourhood on the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce76c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get an idea of the size of the data\n",
    "nrows, ncolumns = df.shape\n",
    "\n",
    "print(f'Found {nrows} calendar lines over a period between '\\\n",
    "      f'{df.date.min().strftime(\"%Y-%m-%d\")} and {df.date.max().strftime(\"%Y-%m-%d\")} '\\\n",
    "      f'for {df.listing_id.unique().size} properties'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the value_counts for property types\n",
    "print((listings.property_type.value_counts().to_frame()\n",
    " .join(\n",
    "     listings.property_type.value_counts(normalize=True)*100,\n",
    "     rsuffix='_percentage'\n",
    " )\n",
    ").to_markdown(floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1659681",
   "metadata": {},
   "source": [
    "The property types seem very skewed, to highlight how skewed these are I will group them in the main 3 categories, House, Apartment, and Other, relabelling everything to Other that is not a House or an Apartment.\n",
    "\n",
    "You could argue that property_types like Townhouse could be counted towards the House property type.\n",
    "\n",
    "#### Introducting `property_category` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['property_category'] = listings.property_type\n",
    "listings.loc[~listings.property_type.isin(['House','Apartment']),'property_category'] = 'Other'\n",
    "listings.property_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ccb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "listings.property_category.value_counts().plot.pie(autopct='%.1f%%',\n",
    "                                                   explode=[0,0,0.2],\n",
    "                                                   pctdistance=0.45,\n",
    "                                                   fontsize=14\n",
    "                                                  )\n",
    "ax.set_ylabel('');\n",
    "sns.reset_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get pricing overview from the calendar\n",
    "min_price = df.price_coalesce.min()\n",
    "max_price = df.price_coalesce.max()\n",
    "mean_price = df.price_coalesce.mean()\n",
    "\n",
    "print(f'Properties are priced between ${min_price:.2f} and ${max_price:.2f} with a average price ${mean_price:.2f} per night from the calendar')\n",
    "\n",
    "## Look at general prices on the listings\n",
    "print(f'The properties are listed with a minimum price of ${listings.price.min():.2f} and maximum of ${listings.price.max():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking at the price distribution over all properties\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.histplot(data=listings, x='price', ax=ax, alpha=0.3);\n",
    "ax.set_xlabel('Price per night ($)')\n",
    "ax.set_ylabel('Number of properties');\n",
    "ax.set_xticks([i for i in range(0,1100,100)])\n",
    "\n",
    "ax.set_title('Distribution of property prices per night')\n",
    "\n",
    "bbox = {'fc': '0.95', 'pad': 0.5, 'ec':'none'}\n",
    "# Add mean\n",
    "x_mean = listings.price.mean()\n",
    "ax.axvline(x=x_mean, linestyle=':', color='green');\n",
    "\n",
    "\n",
    "# Add median\n",
    "x_median = listings.price.median()\n",
    "ax.axvline(x=x_median, linestyle='-.', color='red');\n",
    "\n",
    "\n",
    "# Add IQR\n",
    "q1 = listings.price.quantile(0.25)\n",
    "q3 = listings.price.quantile(0.75)\n",
    "\n",
    "ax.axvspan(q1, q3, color='gray', alpha=0.15);\n",
    "ax.text(200, 325, f' Interquartile Range: \\n \\${q1:.2f} - ${q3:.2f}', bbox=bbox);\n",
    "\n",
    "ax.text(200, 312, f' Mean:   ${x_mean:.2f}       ', rotation=0,\n",
    "        color='green', weight='light', bbox=bbox\n",
    "       )\n",
    "ax.text(200, 297, f' Median: ${x_median:.2f}      ', rotation=0, color='red', weight='light', bbox=bbox);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d59a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the price above we can add a cheap, average or expensive price category to the properties.\n",
    "## The price distribution plot above indicates there is a very wide distribution on the high end,\n",
    "## so a very expensive category seems to be in order for 3 times the 3rd quantile range\n",
    "listings['price_category'] = 'average'\n",
    "listings.loc[listings.price < q1,'price_category'] = 'cheap'\n",
    "listings.loc[listings.price > q3, 'price_category'] = 'expensive'\n",
    "listings.loc[listings.price > q3*3, 'price_category'] = 'very_expensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0083cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More bedrooms means higher prices\n",
    "bedroom_price = listings.pivot_table(index='price_category',columns='bedrooms', values='id', aggfunc='count')\n",
    "bedroom_price_norm = bedroom_price/bedroom_price.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_order = ['cheap','average','expensive','very_expensive']\n",
    "ax = sns.heatmap(bedroom_price_norm.loc[price_order], cmap='rocket', linewidth=0.5);\n",
    "ax.set_ylabel('');\n",
    "# ax.set_yticks([price_order]);\n",
    "ax.set_xlabel('Number of bedrooms');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784dfc5",
   "metadata": {},
   "source": [
    "### Visual data inspectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "plot_df = (df.set_index('date')\n",
    "           .resample('D')\n",
    "           [['price_coalesce']]\n",
    "           .mean()\n",
    "           .rolling(7)\n",
    "           .mean()\n",
    "           .reset_index()\n",
    "          )\n",
    "plot_df.columns = ['date','price']\n",
    "\n",
    "\n",
    "sns.lineplot(x='date',\n",
    "             y='price',\n",
    "             data=plot_df,\n",
    "             ax=ax\n",
    "            )\n",
    "\n",
    "# ax.set_title('7d rolling average price per night', fontsize=20);\n",
    "ax.set_xlabel('Date', fontsize=14)\n",
    "ax.set_ylabel('Price $', fontsize=14);\n",
    "\n",
    "# Add spans for the seasons\n",
    "ax.axvspan(xmin='2016-03-01', xmax='2016-06-01', alpha=0.1, color='green')\n",
    "ax.text(x=pd.to_datetime('2016-04-08'), y=125, s='Spring', fontsize=14)\n",
    "\n",
    "ax.axvspan(xmin='2016-06-01', xmax='2016-09-01', alpha=0.1, color='yellow')\n",
    "ax.text(x=pd.to_datetime('2016-07-08'), y=125, s='Summer', fontsize=14);\n",
    "\n",
    "ax.axvspan(xmin='2016-09-01', xmax='2016-12-01', alpha=0.1, color='orange')\n",
    "ax.text(x=pd.to_datetime('2016-10-08'), y=125, s='Autumn', fontsize=14);\n",
    "\n",
    "ax.axvspan(xmin='2016-12-24', xmax='2016-12-31', alpha=0.1, color='red')\n",
    "ax.text(x=pd.to_datetime('2016-12-22'), y=125, s='Xmas', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_seasonality = (df.pivot_table(index='date', columns='day_of_week', values='price_coalesce', aggfunc='mean')\n",
    "                      .unstack()\n",
    "                      .dropna()\n",
    "                      .reset_index()\n",
    "                     )\n",
    "weekly_seasonality.columns = ['Day of Week','date','Average Price ($)']\n",
    "weekly_seasonality['sort_date'] = weekly_seasonality.date.dt.day_of_week\n",
    "weekly_seasonality.sort_values(by='sort_date', ascending=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "sns.boxplot(x='Day of Week',y='Average Price ($)', data=weekly_seasonality);\n",
    "\n",
    "ax.set_title('Average price per night per day of the week', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebdc61",
   "metadata": {},
   "source": [
    "## Looking at the neighbourhood and price\n",
    "Create a boxplot to display the price differences per neighbourhood group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac049a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the order of the neighbourhoods per price, based on median values\n",
    "neighbourhood_order = (listings.groupby('neighbourhood_group_cleansed')\n",
    "                       .price\n",
    "                       .median()\n",
    "                       .sort_values(ascending=False)\n",
    "                       .index\n",
    "                       .tolist()\n",
    "                      )\n",
    "# Create a boxplot\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot(data=listings, y='neighbourhood_group_cleansed', x='price', orient='h', order=neighbourhood_order)\n",
    "ax.set_ylabel('Neighbourhood (grouped)')\n",
    "ax.set_xlabel('Price ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the order of the neighbourhoods per price and grouped neighbourhood, based on median values\n",
    "neighbourhood_order = (listings.groupby(['neighbourhood_group_cleansed','neighbourhood_cleansed'])\n",
    "                       .price\n",
    "                       .median()\n",
    "                       .to_frame()\n",
    "                       .reset_index()\n",
    "                       .sort_values(by=['neighbourhood_group_cleansed','price'],ascending=False)\n",
    "                       .neighbourhood_cleansed\n",
    "                       .tolist()\n",
    "                      )\n",
    "neighbourhood_order\n",
    "# Create a boxplot\n",
    "fig, ax = plt.subplots(figsize=(12,16))\n",
    "sns.boxplot(data=listings,\n",
    "            y='neighbourhood_cleansed',\n",
    "            x='price',\n",
    "            hue='neighbourhood_group_cleansed',\n",
    "            dodge=False,\n",
    "            orient='h',\n",
    "            order=neighbourhood_order\n",
    "           )\n",
    "\n",
    "ax.legend(title='Neighbourhood (group)')\n",
    "ax.set_ylabel('Neighbourhood')\n",
    "ax.set_xlabel('Price ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69f7aa",
   "metadata": {},
   "source": [
    "# Regression model to predict the price and find important variables\n",
    "\n",
    "\n",
    "## Missing data imputations - part two\n",
    "First have a look at the missing values for the listings. From the barplot below there are a few crucial fields that will have to be filled or dropped. The following columns will be considered \n",
    "\n",
    "- `bedrooms` --> Manual imputation, just a few values\n",
    "- `bathrooms` --> Filled with 1 for NAs, this is the most common value\n",
    "- `beds` --> Filled with 1 for NAs, this is the most common value\n",
    "- `review_score_rating` -> replace with mean value, the reviews all score very high.\n",
    "\n",
    "Only a few missing values for bedrooms etc, use the text from space and summary to see if we can extract the data manually\n",
    "\n",
    "After missing values where filled in the remaining columns with missing values will be dropped as they provide low information, or the information is available in another form (for example, the neighbourhood information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e61c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot missing values\n",
    "(listings.isnull().mean()*100)[~listings.notnull().all()].plot(kind='bar', figsize=(12,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b408d4d",
   "metadata": {},
   "source": [
    "#### Fill in missing values for bedroom, bathroom and beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a829d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms_to_impute = listings[listings.bedrooms.isnull()]['id'].values.tolist()\n",
    "print(bedrooms_to_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39089d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual walkthrough to create the mapping for imputation\n",
    "bedrooms = {\n",
    "    1476298: 0, # Studio --> 1 room so no seperate bedroom\n",
    "    604600: 0, # Studio\n",
    "    1251763: 1, # 1 bed in the living area, 1 bedroom\n",
    "    17951: 0, # Studio\n",
    "    948077: 0, # Space describes 1 room with everything\n",
    "    3272374: 0 # Studio\n",
    "}\n",
    "listings.loc[listings.id.isin(bedrooms_to_impute),['id','summary','space','property_type','bedrooms','bathrooms','beds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all values where imputed\n",
    "for key, value in bedrooms.items():\n",
    "    print(key, value)\n",
    "    listings.loc[listings.id == key,'bedrooms'] = value\n",
    "\n",
    "# Check if values are imputed\n",
    "if listings[listings.bedrooms.isnull()]['id'].values.tolist() == []:\n",
    "    print('all done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137465f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute bathrooms, most common value\n",
    "listings.loc[listings.bathrooms.isnull(),'bathrooms'] = listings.bathrooms.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute beds, most common value\n",
    "listings.loc[listings.beds.isnull(),'beds'] = listings.beds.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e18021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute review score rating with rounded mean\n",
    "listings.loc[listings.review_scores_rating.isnull(),'review_scores_rating'] = listings.review_scores_rating.mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bdaabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9c99d",
   "metadata": {},
   "source": [
    "## Feature Engineering: Selecting the important features\n",
    "Before training the model we'll have a look at the features we currently have.\n",
    "\n",
    "\n",
    "**Identifying columns to remove**\n",
    "- **High percentage missing values**\n",
    "  - As shown above some of these features have over 30% missing values. In these cases the imputation might heavily influence the performance of the regressor. There features will be removed from the dataset.\n",
    "- **Unique**\n",
    "  - Columns like `id`, describing the listing identifier, do not provide general information to be used in the regressor. Being unique they don't contribute to explaining the variance of the data thus they do not add to the performance of the regressor.\n",
    "  - Features like `space` are free text fields, language processing is required to extract more information from this field. In its current raw form it will be dropped as it doesn't add anything to the regressor. Everything with a higher variance of 10% in the features will be dropped\n",
    "- **Only one value**\n",
    "  - Similar to the unique values, columns with only one value do not enrich the regressor with information about the listings. These include fields like `scrape_id`\n",
    "  \n",
    "  \n",
    "**Change boolean columns to int**  \n",
    "The following columns are actually boolean columns, changing the data type to a numeric type like int will eliminate the need to introduce dummy variables for these, reducing the number of features without impacting the information density of the data set.\n",
    "- `instant_bookable`\n",
    "- `require_guest_profile_picture`\n",
    "- `require_guest_phone_verification`\n",
    "\n",
    "**remap `calendar_updated` columns**\n",
    "The `calendar_updated` column tells us something on the amount of time passed since the listing was last updated. As we saw from the plots above, time has a big influence on the price. As its currently provided the column has a lot of different values which spreads out the core information we are interested in. We will map the values to 4 categories:\n",
    "- updated this week\n",
    "- updated this month\n",
    "- updated last 6 months\n",
    "- updated over 6 months ago\n",
    "\n",
    "\n",
    "`host_verfifications` was dropped as a nested field. Before this can be used it needs to be unnested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48068efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect and drop columns with high variances and no variances.\n",
    "col_drop_high_var = []\n",
    "col_drop_no_var = []\n",
    "\n",
    "n_listings = listings.shape[0]\n",
    "for col in listings.columns:\n",
    "    \n",
    "    unique_size = listings[col].unique().size\n",
    "    if unique_size == 1:\n",
    "        col_drop_no_var.append(col)\n",
    "        \n",
    "    ratio = unique_size/n_listings\n",
    "    if ratio > 0.1:\n",
    "        col_drop_high_var.append(col)\n",
    "        \n",
    "    print(f'{col:<35} - {unique_size:<4} - {ratio*100:.1f}%')\n",
    "    \n",
    "print(f'\\nCols to drop due to high variance: {col_drop_high_var}\\nCols to drop due to low variance:  {col_drop_no_var}')\n",
    "\n",
    "## Drop the columns\n",
    "listings_v2 = listings.drop(columns=col_drop_high_var)\n",
    "listings_v2 = listings_v2.drop(columns=col_drop_no_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change type on boolean columns\n",
    "bool_cols = ['instant_bookable','require_guest_profile_picture','require_guest_phone_verification']\n",
    "\n",
    "\n",
    "listings_v2.loc[:, bool_cols] = listings_v2[bool_cols].replace({'t':1,'f':0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afe0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map the calender_update to a list of values\n",
    "calender_update_map = {}\n",
    "for value in listings_v2.calendar_updated.unique():\n",
    "    replace = 'over 6 months'\n",
    "    \n",
    "    if 'day' in value:\n",
    "        replace = 'this week'\n",
    "    elif 'week ago' in value or value == '2 weeks ago' or value == '3 weeks ago' or value == '4 weeks ago':\n",
    "        replace = 'this month'\n",
    "    elif 'week' in value or value == '2 months ago' or value == '3 months ago' or value == '4 months ago' or value == '5 months ago':\n",
    "        replace = 'last 6 months'\n",
    "        \n",
    "    calender_update_map[value] = replace\n",
    "\n",
    "listings_v2['calendar_updated_clean'] = listings_v2.calendar_updated.replace(calender_update_map)\n",
    "listings_v2.calendar_updated_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd37362",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.columns.tolist()\n",
    "feature_cols = ['neighbourhood_cleansed',\n",
    "                 'neighbourhood_group_cleansed',\n",
    "                 'property_type',\n",
    "                 'room_type',\n",
    "                 'accommodates',\n",
    "                 'bathrooms',\n",
    "                 'bedrooms',\n",
    "                 'beds',\n",
    "                 'bed_type',\n",
    "                 'price',\n",
    "                 'minimum_nights',\n",
    "                 'maximum_nights',\n",
    "                 'number_of_reviews',\n",
    "                 'review_scores_rating',\n",
    "                 'property_category'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77af90",
   "metadata": {},
   "source": [
    "# RandomForest regressor\n",
    "- Describe the regression columns picked to include for feature importance\n",
    "  - Most of the columns are numerical values, so easy to user without dummy variables\n",
    "  - Some of the variables cut out are either `unique values`, have a terrible `skewed distribution` or have 1 value for everything\n",
    "- Show the important ranked feateres sorted from low to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e28dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, y_col='price'):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no prices\n",
    "    2. Create X as all the columns that are not the price column\n",
    "    3. Create y as the price column\n",
    "    4. Drop any price related columns from X\n",
    "    6. Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "    '''\n",
    "    # Drop rows with missing salary values\n",
    "    y = df[y_col]\n",
    "    \n",
    "    #Drop respondent and expected salary columns\n",
    "    df = df.drop(columns=[y_col])\n",
    "    \n",
    "    # Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "        \n",
    "    # Dummy the categorical variables\n",
    "    cat_vars = df.select_dtypes(include=['object']).copy().columns\n",
    "    for var in  cat_vars:\n",
    "        # for each cat add dummy var, drop original column\n",
    "        df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "    \n",
    "    X = df\n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y\n",
    "X, y = clean_data(listings)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selected regression_cols, after testing these performed the best\n",
    "\n",
    "regression_cols = [\n",
    "    'neighbourhood_group_cleansed',\n",
    "    'property_category',\n",
    "    'cancellation_policy',\n",
    "    'review_scores_rating',\n",
    "    'availability_365',\n",
    "    'calculated_host_listings_count',\n",
    "    'room_type',\n",
    "    'accommodates',\n",
    "    'bathrooms',\n",
    "    'bedrooms',\n",
    "    'number_of_reviews',\n",
    "    'calendar_updated_clean',\n",
    "    'price' # y_value\n",
    "                  ]\n",
    "listings_v2.drop(columns='price_category', inplace=True) # Drop the price category\n",
    "\n",
    "\n",
    "#define dataset\n",
    "X, y = clean_data(listings_v2[regression_cols])\n",
    "\n",
    "# Split train/test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 600 trees, 300 performed worse, so did 1000. Picked a value in the middle\n",
    "forest = RandomForestRegressor(n_estimators=600,)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# r2 score, between 0 and 1 (can be negative if the model is really bad).\n",
    "# Describes the % of variance caught, so the closer to 1 the better the model\n",
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance ranking, Add color per \"group\". Groups here are made by hand\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "feature_ranks = pd.DataFrame(data={'feature':X.columns.tolist(), 'importance':forest.feature_importances_})\n",
    "feature_ranks = feature_ranks.sort_values(by='importance', ascending=True).tail(7)\n",
    "\n",
    "color = ['#9467bd','#2ca02c','#2ca02c','#ff7f0e','#1f77b4','#1f77b4','#1f77b4']\n",
    "\n",
    "plt.barh(feature_ranks.feature, feature_ranks.importance, color=color, alpha=0.9);\n",
    "\n",
    "# ax.set_title('Seven most important features in the Randomforest Regressor');\n",
    "ax.set_ylabel('Feature');\n",
    "ax.set_xlabel('Feature weight');\n",
    "ax.xaxis.grid(True, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75f332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
